{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6cd1275e",
      "metadata": {
        "id": "6cd1275e"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7e4a7ca8",
      "metadata": {
        "id": "7e4a7ca8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bcdba088",
      "metadata": {
        "id": "bcdba088"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1d4ec862",
      "metadata": {
        "id": "1d4ec862"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, Model, Sequential, callbacks, losses, optimizers, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "660b78c5",
      "metadata": {
        "id": "660b78c5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from IPython import display\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f72183fa",
      "metadata": {
        "id": "f72183fa"
      },
      "source": [
        "# Vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "efca1eca",
      "metadata": {
        "id": "efca1eca"
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = int(10e1)\n",
        "BATCH_SIZE = 2**5\n",
        "BUFFER_SIZE = 100000\n",
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f51bad4",
      "metadata": {
        "id": "8f51bad4"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f57a7b66",
      "metadata": {
        "id": "f57a7b66"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (_, _) = datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "train_images = (train_images) / 255.0\n",
        "\n",
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_images)\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2db21e75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2db21e75",
        "outputId": "e4aa5353-7f0b-41a0-ce60-550980fcecc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9950cc4f",
      "metadata": {
        "id": "9950cc4f"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "434faba5",
      "metadata": {
        "id": "434faba5"
      },
      "outputs": [],
      "source": [
        "class Generator(Model):\n",
        "    \"\"\"\n",
        "    Генератор Keras. Принимает тензор размерности (batch_size, LATENT_DIM)\n",
        "\n",
        "    Цель - генерировать изображения, неотличимые от настоящих цифр MNIST\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Последовательность слоев\n",
        "        self.dense_blocks = Sequential(\n",
        "            [\n",
        "                layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(LATENT_DIM,)),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.ReLU(),\n",
        "\n",
        "                layers.Reshape((7, 7, 256)),\n",
        "\n",
        "                layers.Conv2DTranspose(\n",
        "                    128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False\n",
        "                ),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.ReLU(),\n",
        "\n",
        "                layers.Conv2DTranspose(\n",
        "                    64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False\n",
        "                ),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.ReLU(),\n",
        "\n",
        "                layers.Conv2DTranspose(\n",
        "                    1,\n",
        "                    (5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"same\",\n",
        "                    use_bias=False,\n",
        "                    activation=\"sigmoid\",\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense_blocks(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1861f11c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "1861f11c",
        "outputId": "28e62372-6ea8-43a9-d466-1cb87d679eba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def draw_image(image, image_shape):\n",
        "\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    if image_shape[-1] == 1:  # Градации серого\n",
        "        plt.imshow(image[0, :, :, 0], cmap=\"gray\")\n",
        "    else:  # RGB или другие форматы\n",
        "        plt.imshow((image[0] * 255).astype(np.uint8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Создание экземпляра генератора\n",
        "\n",
        "generator = Generator()\n",
        "\n",
        "noise = tf.random.normal([1, LATENT_DIM])\n",
        "generated_image = generator(noise, training=False)\n",
        "draw_image(generated_image, generated_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d61665",
      "metadata": {
        "id": "44d61665"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "992b39da",
      "metadata": {
        "id": "992b39da"
      },
      "outputs": [],
      "source": [
        "class Discriminator(Model):\n",
        "    \"\"\"\n",
        "    Дискриминатор Keras. Принимает тензор размерности (batch_size, 784)\n",
        "    и возвращает тензор размерности (batch_size, 1) с вероятностями принадлежности\n",
        "    к реальным данным\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dense_blocks = Sequential(\n",
        "            [\n",
        "                layers.Conv2D(\n",
        "                    64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1]\n",
        "                ),\n",
        "                layers.ReLU(),\n",
        "                layers.Dropout(0.3),\n",
        "                layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"),\n",
        "                layers.ReLU(),\n",
        "                layers.Dropout(0.3),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense_blocks(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fbcfb673",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbcfb673",
        "outputId": "422d26bb-8537-4223-a0bc-293f34eb9b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.04352773]], dtype=float32)>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminator = Discriminator()\n",
        "decision = discriminator(generated_image)\n",
        "decision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf55970f",
      "metadata": {
        "id": "cf55970f"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "180831f6",
      "metadata": {
        "id": "180831f6"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(callbacks.Callback):\n",
        "    def __init__(self, gan_model, test_noise):\n",
        "        super().__init__()\n",
        "        self.gan = gan_model\n",
        "        self.test_noise = test_noise\n",
        "        self.test_progression = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Генерация и сохранение изображений\n",
        "        generated_images = self.gan.generator(self.test_noise)\n",
        "        self.test_progression.append(generated_images.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4f78fd10",
      "metadata": {
        "id": "4f78fd10"
      },
      "outputs": [],
      "source": [
        "class GAN(Model):\n",
        "    def __init__(self):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = Generator()\n",
        "        self.discriminator = Discriminator()\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer, g_loss, d_loss):\n",
        "        super(GAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_loss = g_loss\n",
        "        self.d_loss = d_loss\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        noise = tf.random.normal((BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "        # Используем self-модели вместо глобальных переменных\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = self.generator(noise, training=True)\n",
        "\n",
        "            real_output = self.discriminator(real_images, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            ge_loss = self.g_loss(fake_output)\n",
        "            di_loss = self.d_loss(real_output, fake_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(\n",
        "            ge_loss, self.generator.trainable_variables\n",
        "        )\n",
        "        gradients_of_discriminator = disc_tape.gradient(\n",
        "            di_loss, self.discriminator.trainable_variables\n",
        "        )\n",
        "\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gradients_of_generator, self.generator.trainable_variables)\n",
        "        )\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(gradients_of_discriminator, self.discriminator.trainable_variables)\n",
        "        )\n",
        "\n",
        "        return {\"d_loss\": di_loss, \"g_loss\": ge_loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38680426",
      "metadata": {
        "id": "38680426"
      },
      "source": [
        "# Funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "90bd551f",
      "metadata": {
        "id": "90bd551f"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input, path):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(7, 7))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 255, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.savefig(os.path.join(path, \"image_at_epoch_{:04d}.png\".format(epoch)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ff9e12af",
      "metadata": {
        "id": "ff9e12af"
      },
      "outputs": [],
      "source": [
        "cross_entropy = losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "generator_optimizer = optimizers.Adam(learning_rate=1e-4)\n",
        "discriminator_optimizer = optimizers.Adam(learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f6613df0",
      "metadata": {
        "id": "f6613df0"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = \"./checkpoints_b\"\n",
        "img_dir = \"./images_b\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19b43637",
      "metadata": {
        "id": "19b43637"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6e288d19",
      "metadata": {
        "id": "6e288d19"
      },
      "outputs": [],
      "source": [
        "SEED = tf.random.normal([16, LATENT_DIM])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53dc6b70",
      "metadata": {
        "id": "53dc6b70"
      },
      "outputs": [],
      "source": [
        "def train(model: GAN, dataset, epochs: int):\n",
        "    count_batches = len(dataset)\n",
        "    print(f\"total epochs: {epochs}\")\n",
        "    print()\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"epoch {epoch + 1} / {epochs}\")\n",
        "\n",
        "        # start = time.time()\n",
        "\n",
        "        for index_batch, image_batch in enumerate(dataset):\n",
        "            print(f\"{index_batch + 1} / {count_batches}\")\n",
        "            model.train_step(image_batch)\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(model.generator, epoch + 1, SEED, img_dir)\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "        # print (f'Time for epoch {epoch + 1} is {time.time() - start} sec')\n",
        "    print()\n",
        "\n",
        "    # display.clear_output(wait=True)\n",
        "    generate_and_save_images(model.generator, epochs, SEED, img_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "09529604",
      "metadata": {
        "id": "09529604"
      },
      "outputs": [],
      "source": [
        "gan = GAN()\n",
        "gan.compile(\n",
        "    g_optimizer=generator_optimizer,\n",
        "    d_optimizer=discriminator_optimizer,\n",
        "    g_loss=generator_loss,\n",
        "    d_loss=discriminator_loss,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ca1d08a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ca1d08a2",
        "outputId": "7e995122-55c4-4c15-cb50-2a5135f39ee5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAIvCAYAAACFs4ofAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAex0lEQVR4nO3d649V5f028L1hBoZBYJDzWQGVo7RVKxX4gZUmtRKtiW/0f2lSY03tKdFYo1FT2yalrbG+aGsbjfVQgUDlJHKsyGkQOQ0IDDgMw+zn9b32evZQkr32/g6fz7sra5b5Rm8Xl/fcrlWuVCqVEgBAMEMaPQAAwPVQYgCAkJQYACAkJQYACEmJAQBCUmIAgJCUGAAgJCUGAAhJiQEAQmq51h8sl8v1nIMGqfcLm62bwame68aaGZw8a7geA60bOzEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAITU0ugBIhg7dmySz54926BJiGTcuHFJ7urqatAkRDFp0qQknzhxokGTEMnUqVOTfOzYsQZNUjw7MQBASEoMABCSEgMAhORMTI4f//jHSb7llluS/JOf/KTqnv3799dxIiJ4+umnkzxhwoQkP/vss1X37N69u54j0eSefPLJJM+aNSvJL730UtU9GzdurOtMNL+nnnoqyZMnT05y3rrZsmVLXWdqFDsxAEBISgwAEJISAwCE5ExMju7u7iRn393Q19dX5DgEcenSpSRPmTIlyf39/UWOQwAXLlxI8syZM5Pc09NT5DgEkX3WjB8/PsmXL18ucpyGshMDAISkxAAAISkxAEBIzsRcg+9///tJnjNnTtXPHDp0qKBpaFYXL15M8po1a5L8wgsvVN2zd+/eus5EcyuXy0m+//77k5x9/weUSqVSb29vkh955JEkv/jii1X37Ny5s64zNYqdGAAgJCUGAAhJiQEAQlJiAICQHOzNMWbMmJrXv/rqq2IGIZQRI0bUvH7+/PmCJiGKsWPH1ryeffEmlErVH5fNyv5PBoOZnRgAICQlBgAISYkBAEJyJiZHW1tbkrMf7lu6dGnVPVu2bKnrTDS/9vb2JGc/FLp48eKqezZs2FDXmWhu2XNU2TWzaNGiqnvWrVtX15lofq2trUm+cuVKkhcuXFh1z/r16+s6U6PYiQEAQlJiAICQlBgAICRnYnJ0dnYmuaurK8kfffRRkeMQ1OnTp5Ps3BRZ586dS/KZM2eSvHnz5iLHIYhKpZLkkydPJnnXrl1FjtNQdmIAgJCUGAAgJCUGAAjJmZgcDz74YJLHjRuX5JtuuqnIcQhixYoVSc5+32T48OFFjkMAq1atSvL48eOT7FlDnrvvvjvJkydPTvLo0aOLHKeh7MQAACEpMQBASEoMABCSEgMAhORgb47p06cn+erVq0l2QJM8U6ZMSXL2o2wtLf51I5VdM9kPQGY/RgulUvX/bJL9M2rYsGFFjtNQdmIAgJCUGAAgJCUGAAjJL+lzbNiwIcmzZs1Kst9Tkye7biZNmpTkMWPGFDkOAWQ/8Jg9IzNy5MgixyGIHTt2JHnmzJlJ7ujoKHCaxrITAwCEpMQAACEpMQBASM7E5Dh06FCS9+3bl+Q9e/YUOA1RfPnll0netWtXkg8cOFDkOATQ2dmZ5E8++STJ2TUEpVKp9MUXXyQ5u06y62gwsxMDAISkxAAAISkxAEBIzsTkGDp0aJLvuuuuJK9Zs6bqnl//+td1nYnm19ramuSlS5cmefXq1VX37Ny5s64z0dyy74VZtmxZkletWlV1z969e+s5EgFknzX33ntvkvOeNdu3b6/nSA1jJwYACEmJAQBCUmIAgJCcicmxYMGCJJfL5QZNQiTz5s1L8pAh6X8j9PX1FTkOAcydOzfJ2WdN9nwelEql0uzZs5OcfdbcSH9m2YkBAEJSYgCAkJQYACAkJQYACMnB3hyvv/56kh9//PEk33HHHUWOQxBvvvlmkrMvRZw6dWqR4xDAn/70pyTfd999SZ4zZ06R4xDEX/7ylyQ//PDDSZ45c2aR4zSUnRgAICQlBgAISYkBAEJyJiZH9kVBV65cSXL295FQKpVKlUolyT09PUl+7733ihyHALLPmt7e3iR71pAn+2dS9lnz97//vchxGspODAAQkhIDAISkxAAAITkTk+POO+9Mcmtra5LHjRtX5DgEsWTJkiS3tbUl2boha/78+UkeNmxYkvPeE7N+/fq6zkTzy36kOPusmTVrVpHjNJSdGAAgJCUGAAhJiQEAQnImJsfixYtrXh89enRBkxDJQN/Uam9vL2gSopg9e3bN685RkWfevHk1r998880FTdJ4dmIAgJCUGAAgJCUGAAjJmZgchw8frnk9+y4HKJVKpYMHD9a83tLiXzdSR44cqXm9u7u7oEmI5NixYzWv9/X1FTRJ49mJAQBCUmIAgJCUGAAgJCUGAAjJScMcBw4cqHn93XffLWgSIjl9+nTN6++9915BkxBFV1dXzevvvPNOQZMQyfHjx2te/8c//lHQJI1nJwYACEmJAQBCUmIAgJCcickx0NmGzz//vKBJiOT8+fM1r1s3ZF24cKHm9YFevMmNqbe3t+b13bt3FzRJ49mJAQBCUmIAgJCUGAAgpHKlUqlc0w+Wy/WehQa4xn/81826GZzquW6smcHJs4brMdC6sRMDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEFK5UqlUGj0EAMD/yk4MABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACG1XOsPlsvles5Bg1Qqlbr+9a2bwame68aaGZw8a7geA60bOzEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAITU0ugBIhg7dmySz54926BJiGTq1KlJPnbsWIMmIQrPGq7HjBkzktzZ2dmgSYpnJwYACEmJAQBCUmIAgJCcicnxox/9KMnjx49P8iuvvFJ1z86dO+s6E83vmWeeSfLEiROT/NJLL1Xd85///KeuM9HcnnzyySRnz1H96le/qrpn7969dZ2J5vfTn/40ydl188ILL1TdM1ifNXZiAICQlBgAICQlBgAIyZmYHEePHk3yvHnzktzT01PkOATx1VdfJTm7bi5dulTgNESQXROTJ09Ocl9fX5HjEER23YwZMybJ58+fL3KchrITAwCEpMQAACEpMQBASM7E5Ojv70/yE088keRXX3216p79+/fXdSaaX6VSSfLDDz+c5N/85jdV93i/0I2tt7c3yWvWrEnyc889V3WPZw3Zs1KPPPJIkl988cWqewbr+4XsxAAAISkxAEBISgwAEJISAwCE5GBvjuyLg7LOnTtX0CRE0tHRUfP6mTNnihmEMAZ61nz99dcFTUIkAz1rLl68WMwgTcBODAAQkhIDAISkxAAAITkTk2P06NFJzr5YaNGiRVX3bN26ta4z0fza2tqSnH2R2eLFi6vuWbduXV1norll10z2WbNgwYKqe9avX1/XmWh+5XI5yVeuXEnykiVLqu4ZrM8aOzEAQEhKDAAQkhIDAITkTEyO8+fPJ/nUqVNJ3r59e4HTEMXJkyeTfOLEiSTv2LGjyHEIIPvOqePHjyd527ZtRY5DEJcuXUryl19+meSNGzcWOU5D2YkBAEJSYgCAkJQYACAkZ2JyrFmzJsmTJk1Kcnt7e5HjEMT999+f5KlTpyb5pptuKnIcAli5cmWSs2umpcUjmmrLli1L8rRp05KcfdfZYGYnBgAISYkBAEJSYgCAkJQYACAkp8ZyzJgxI8lXr15NcvajbVAqVR+uy66bIUP8NwOpmTNnJjm7ZhwGJ8/kyZOT3N/fn+Thw4cXOU5DeaoCACEpMQBASEoMABCSMzE5Nm3alOTp06cn+UZ6kRDXbsuWLUnOvrjMWSqy3n///SRnz+O1trYWOQ5BZD9CPGvWrCSPGDGiwGkay04MABCSEgMAhKTEAAAhOROTo7OzM8n//e9/k7xr164ixyGIo0ePJjl7RubTTz8tchwC2LlzZ5Kza2bPnj1FjkMQR44cSXL2jMyN9KyxEwMAhKTEAAAhKTEAQEjOxOTo6OhI8je/+c0kL126tOqezz//vJ4jEcDYsWOTfP/99yd52bJlVffs37+/rjPR3CZMmJDk//u//0tydg2VSqXSa6+9VteZaH7jxo1L8vLly5O8YsWKqnsG67PGTgwAEJISAwCEpMQAACE5E5Nj4cKFSS6Xy0m+ePFikeMQxNy5c5M8ZEj63wi+g0PW4sWLk5x91kCegf6MGjp0aJHjNJSdGAAgJCUGAAhJiQEAQlJiAICQHOzN8fvf/z7J2RdO3XLLLQVOQxRr165N8gMPPJDk7MFfePPNN5P82GOPJXn27NlFjkMQr7/+epKzL7u77bbbihynoezEAAAhKTEAQEhKDAAQkjMxOb7++uskX758OcnvvPNOkeMQRE9PT838/vvvFzkOAVy4cCHJfX19Sf7nP/9Z5DgEcenSpST39vYm+a233ipynIayEwMAhKTEAAAhKTEAQEjOxOS45557kjx8+PAkL1iwoOqe3bt313Umml/2Y34jRoxI8oQJE4ochwCy7/doaUkfyXPmzKm6Z8OGDXWdiea3ZMmSJA8bNizJU6dOLXKchrITAwCEpMQAACEpMQBASM7E5PjGN75R8/qtt95azCCEMn/+/JrX29vbC5qEKO6+++6a17NnZKBUGvg7bCNHjixoksazEwMAhKTEAAAhKTEAQEh+4Zrj4MGDNa9XKpWCJiGSEydO1Lw+ZIj/ZiA10LPmzJkzBU1CJIcOHap5vb+/v5hBmoCnKgAQkhIDAISkxAAAISkxAEBIDvbmOH36dM3rb7zxRkGTEMnZs2drXn///fcLmoQoDhw4UPP6Rx99VNAkRNLZ2Vnz+r/+9a+CJmk8OzEAQEhKDAAQkhIDAITkTEyOrq6umtcHetEQN6be3t6a1/ft21fQJERx6tSpmte97I483d3dNa8fOXKkoEkaz04MABCSEgMAhKTEAAAhlSvX+DXDcrlc71logHp/zNK6GZzquW6smcHJs4brMdC6sRMDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEFK5UqlUGj0EAMD/yk4MABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCE1HKtP1gul+s5Bw1SqVTq+te3bganeq4ba2Zw8qzhegy0buzEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQUkujB4hg6tSpST527FiDJiGSGTNmJLmzs7NBkxDFzJkzk3zkyJEGTUIk48aNS3JXV1eDJimenRgAICQlBgAISYkBAEJyJibH008/neSJEycm+YUXXqi6Z/v27fUciQB++ctfJjn7e+q8dbN58+a6zkRze+qpp5I8bdq0JOetmS1bttR1JprfM888k+TJkycn+dlnn626Z7D+GWUnBgAISYkBAEJSYgCAkJyJyXHp0qUkZ8/E9Pb2FjkOQZw9ezbJs2bNSnJPT0+R4xDAuXPnkjxnzpwkd3d3FzkOQZw4cSLJd9xxR5JvpHVjJwYACEmJAQBCUmIAgJCciclRLpeT/PDDDyf5+eefr7pn9+7ddZ2J5tfa2prkxx57LMmvvPJK1T07d+6s60w0t0qlkuTHH388ya+99lrVPfv27avrTMTzwx/+MMkvv/xy1c/s37+/oGmKZScGAAhJiQEAQlJiAICQlBgAICQHe3OMGTOm5nUvLSPPhAkTal7v6uoqaBKiGDlyZM3r2RcoQqlUKnV0dNS8fubMmWIGaQJ2YgCAkJQYACAkJQYACMmZmGtw5cqVJC9cuLDqZ9atW1fUODSptra2JPf19SX5zjvvrLpny5YtdZ2J5pY9R5VdM0uWLKm6Z/PmzXWdieY3fPjwJGfXzaJFi6ru2bRpU11nahQ7MQBASEoMABCSEgMAhORMTI7se2BOnTqV5E8++aTIcQgi+26G48ePJ9m6IevixYtJzq6ZXbt2FTkOQWTfH5T9M2qwnn/JYycGAAhJiQEAQlJiAICQnInJcd999yV50qRJSR7o20rcmFauXJnkKVOmJLm9vb3IcQhgxYoVSc6umZtuuqnIcQhizZo1SZ48eXKSb6R1YycGAAhJiQEAQlJiAICQlBgAICQHe3NMnDgxydkPQLa0+NtGtZtvvjnJ2Y+ytba2FjkOAWQPZF69ejXJlUqlyHEIIrtu+vv7kzxs2LAix2koOzEAQEhKDAAQkhIDAITkcEeObdu2JXnGjBlJbmtrK3Icgsh+dG3s2LFJHj16dJHjEMDHH3+c5Oy5Ki9IJM8HH3yQ5GnTpiW5o6OjuGEazE4MABCSEgMAhKTEAAAhOROT4+DBg0n+5JNPamYolUqlL774Isnbt29P8meffVbgNERw9OjRJGfPyOzZs6fIcQji8OHDSd6xY0fNPJjZiQEAQlJiAICQlBgAICRnYnJMmjQpycuXL0/yQw89VHXPc889V9eZaH7ZbyOtWrUqyd/5zneq7tm9e3c9R6LJZd8D88ADDyR5xYoVVffs37+/rjPR/EaNGpXkb3/720levXp11T2vvvpqXWdqFDsxAEBISgwAEJISAwCE5ExMjgULFiR5yJC067W0+NtGtdtvvz3J2XVz5cqVIschgLlz5yY5u2ayGUqlUum2225LcrlcbtAkjeffEAAgJCUGAAhJiQEAQlJiAICQnFDN8frrryc5+8KpefPmFTkOQbzxxhtJ/sEPfpDk7GE8+OMf/5jk733ve0mePXt2keMQxNq1a5P86KOPJvlGWjd2YgCAkJQYACAkJQYACMmZmBwXL15Mcm9vb5KzZ2agVCqVuru7k9zT05Pkt99+u8hxCKCvry/J2TXz3nvvFTkOQXz99ddJvnz5cpL/+te/FjlOQ9mJAQBCUmIAgJCUGAAgJGdicixevDjJw4YNS/KN9P/gc+2y66atrS3J48ePL3IcAliyZEmSs2tm4sSJRY5DEEuXLk3y8OHDkzxr1qyqezZu3FjXmRrFTgwAEJISAwCEpMQAACE5E5NjoG/cjBgxoqBJiGT+/Pk1r2fPVsGiRYtqXq9UKgVNQiQLFy6seX3ChAkFTdJ4dmIAgJCUGAAgJCUGAAjJmZgcXV1dNa9funSpoEmI5Pjx440egWA6OztrXi+XywVNQiQDPWuy3/8bzOzEAAAhKTEAQEhKDAAQkhIDAITkYG+OgQ72vvXWWwVNQiTHjh2reX3dunUFTUIUp0+frnl9/fr1BU1CJIcOHap5/d133y1mkCZgJwYACEmJAQBCUmIAgJCcickx0O+pv/jii4ImIZKBXjA10JkZbjwnTpyoef3IkSMFTUIko0aNqnl9oJcoDiZ2YgCAkJQYACAkJQYACKlcqVQq1/SDPkQ2KF3jP/7rZt0MTvVcN9bM4ORZw/UYaN3YiQEAQlJiAICQlBgAICQlBgAISYkBAEJSYgCAkJQYACAkJQYACEmJAQBCUmIAgJCUGAAgJCUGAAhJiQEAQlJiAICQlBgAICQlBgAIqVypVCqNHgIA4H9lJwYACEmJAQBCUmIAgJCUGAAgJCUGAAhJiQEAQlJiAICQlBgAICQlBgAISYkBAEJSYgCAkJQYACAkJQYACEmJAQBCUmIAgJCUGAAgJCUGAAhJiQEAQlJiAICQlBgAICQlBgAISYkBAEJSYgCAkFqu9QfL5XI956BBKpVKXf/61s3gVM91Y80MTp41XI+B1o2dGAAgJCUGAAhJiQEAQlJiAICQlBgAICQlBgAISYkBAEJSYgCAkJQYACAkJQYACEmJAQBCUmIAgJCUGAAgJCUGAAhJiQEAQmpp9AARjBs3LsldXV0NmoRIbrnlliQfOnSoIXMQx8SJE5N88uTJBk1CJBMmTEjyqVOnGjRJ8ezEAAAhKTEAQEhKDAAQkjMxOX7xi18kOft76ueff77qns2bN9d1Jprfz372sySPGjUqyb/73e+q7tm0aVNdZ6K5Pf3000nOnm347W9/W3XPhg0b6jkSAfz85z9P8tixY5P83HPPVd2zc+fOus7UKHZiAICQlBgAICQlBgAIyZmYHL29vUnO/p66u7u7yHEI4quvvkry9OnTk3z58uUCpyGC7LMk+26h7JqCUqlUOnfuXJLnzp2b5L6+viLHaSg7MQBASEoMABCSEgMAhORMTI7+/v4kP/jgg0nO+3/w9+7dW9eZaH6tra1Jfvzxx5O8du3aqnu2b99ez5Foci0t6SP4iSeeSPKrr75adc/u3bvrOhPN7+rVq0l+9NFHk/zyyy9X3TNY/4yyEwMAhKTEAAAhKTEAQEhKDAAQkoO9OTo6Ompev3jxYjGDEMqYMWNqXu/q6ipoEqIY6FmTfakZlEql0vDhw2teP3v2bEGTNJ6dGAAgJCUGAAhJiQEAQnImJsfQoUOTnP2Y1l133VV1z7p16+o6E/H09PQkedGiRVU/s3HjxqLGoQmVy+UkX7lyJcn33ntv1T1bt26t60w0v7a2tiRn183dd99ddc+mTZvqOlOj2IkBAEJSYgCAkJQYACAkZ2JynD59OskXLlxIso/2kae7uzvJBw8eTLJ1Q9bhw4eTfOLEiSTv2LGjyHEIKrtutm3b1qBJimcnBgAISYkBAEJSYgCAkJyJybF8+fIkZ79v0t7eXuA0RLFy5cokz507N8kDfVuJG8+KFSuSPHny5CQP9G0lbkzZP6OmTJmS5Bvpzyg7MQBASEoMABCSEgMAhKTEAAAhOdibY9q0aUm+evVqkvv7+4schyAmTJiQ5OyHQyEr+6zJfsjPGiLP9OnTk5z9M+pGYicGAAhJiQEAQlJiAICQnInJsWXLliRnf/84evToIschiE2bNiV53LhxSR45cmSR4xDA5s2bk3zHHXckecSIEUWOQxBbt25N8tixY5N8I60bOzEAQEhKDAAQkhIDAITkTEyOzz//PMnZ3z9u27atyHEIorOzM8kff/xxkvfv31/kOARw4MCBJGfP423fvr3AaYji5MmTSf7000+TvGfPniLHaSg7MQBASEoMABCSEgMAhORMTI7x48cnedmyZUlevXp11T3OOzBq1KgkP/jgg0l+8803q+7ZvXt3XWeiuXV0dCT5u9/9bpKXL19edc+hQ4fqOBERZN85dd999yV55cqVVfcM1j+j7MQAACEpMQBASEoMABCSMzE55s2bl+RyuZzk/v7+IschiNtuuy3JQ4cOTfKVK1eKHIcAvvWtbyV5yJD0vyvb29uLHIcgZs6cmeTsuvHtJACAJqfEAAAhKTEAQEhKDAAQkoO9Of7whz8kedWqVUmeM2dOgdMQRfZldg899FCSb7311iLHIYDsmlmzZk2SZ8yYUeQ4BLF27dokZ19uN3fu3CLHaSg7MQBASEoMABCSEgMAhORMTI4LFy4k+fLly0n+29/+VuQ4BFGpVJLc3d2d5A8//LDIcQigp6cnydlnzb///e8ixyGI7AtXe3t7k/z2228XOU5D2YkBAEJSYgCAkJQYACAkZ2Jy3HPPPUkePnx4kmfPnl11z7p16+o6E83vzjvvTPKoUaOSPGXKlCLHIYDs+z2yz5rx48cXOQ5BzJ8/P8nDhg1L8sSJE4scp6HsxAAAISkxAEBISgwAEJIzMTkWLFhQ83pHR0cxgxDKzJkza17PvtsBfIeN63H77bfXvN7e3l7QJI1nJwYACEmJAQBCUmIAgJCciclx8ODBmtfb2toKmoRIDh06VPN69rs4sHfv3iSvXr06yS0tHtFUO3r0aM3rV69eLWiSxrMTAwCEpMQAACEpMQBASEoMABCSU2M5jh07VvP6n//854ImIZLsYbtKpZLkrVu3FjkOAXz22Wc1r3/wwQfFDEIop0+frnn9ww8/LGiSxrMTAwCEpMQAACEpMQBASM7E5BjoRUGHDx8uaBIiaW1tTXK5XE7yQC+o4sZz/vz5mtc7OzsLmoRIBnpx5r59+wqapPHsxAAAISkxAEBISgwAEFK5kn2Zxf/vBzO/32dwuMZ//NfNuhmc6rlurJnBybOG6zHQurETAwCEpMQAACEpMQBASEoMABCSEgMAhKTEAAAhKTEAQEhKDAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABBSuVKpVBo9BADA/8pODAAQkhIDAISkxAAAISkxAEBISgwAEJISAwCEpMQAACEpMQBASEoMABDS/wPwJ/zuHLfYPAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 700x700 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 45 / 100\n",
            "1 / 1875\n",
            "2 / 1875\n",
            "3 / 1875\n",
            "4 / 1875\n",
            "5 / 1875\n",
            "6 / 1875\n",
            "7 / 1875\n",
            "8 / 1875\n",
            "9 / 1875\n",
            "10 / 1875\n",
            "11 / 1875\n",
            "12 / 1875\n",
            "13 / 1875\n",
            "14 / 1875\n",
            "15 / 1875\n",
            "16 / 1875\n",
            "17 / 1875\n",
            "18 / 1875\n",
            "19 / 1875\n",
            "20 / 1875\n",
            "21 / 1875\n",
            "22 / 1875\n",
            "23 / 1875\n",
            "24 / 1875\n",
            "25 / 1875\n",
            "26 / 1875\n",
            "27 / 1875\n",
            "28 / 1875\n",
            "29 / 1875\n",
            "30 / 1875\n",
            "31 / 1875\n",
            "32 / 1875\n",
            "33 / 1875\n",
            "34 / 1875\n",
            "35 / 1875\n",
            "36 / 1875\n",
            "37 / 1875\n",
            "38 / 1875\n",
            "39 / 1875\n",
            "40 / 1875\n",
            "41 / 1875\n",
            "42 / 1875\n",
            "43 / 1875\n",
            "44 / 1875\n",
            "45 / 1875\n",
            "46 / 1875\n",
            "47 / 1875\n",
            "48 / 1875\n",
            "49 / 1875\n",
            "50 / 1875\n",
            "51 / 1875\n",
            "52 / 1875\n",
            "53 / 1875\n",
            "54 / 1875\n",
            "55 / 1875\n",
            "56 / 1875\n",
            "57 / 1875\n",
            "58 / 1875\n",
            "59 / 1875\n",
            "60 / 1875\n",
            "61 / 1875\n",
            "62 / 1875\n",
            "63 / 1875\n",
            "64 / 1875\n",
            "65 / 1875\n",
            "66 / 1875\n",
            "67 / 1875\n",
            "68 / 1875\n",
            "69 / 1875\n",
            "70 / 1875\n",
            "71 / 1875\n",
            "72 / 1875\n",
            "73 / 1875\n",
            "74 / 1875\n",
            "75 / 1875\n",
            "76 / 1875\n",
            "77 / 1875\n",
            "78 / 1875\n",
            "79 / 1875\n",
            "80 / 1875\n",
            "81 / 1875\n",
            "82 / 1875\n",
            "83 / 1875\n",
            "84 / 1875\n",
            "85 / 1875\n",
            "86 / 1875\n",
            "87 / 1875\n",
            "88 / 1875\n",
            "89 / 1875\n",
            "90 / 1875\n",
            "91 / 1875\n",
            "92 / 1875\n",
            "93 / 1875\n",
            "94 / 1875\n",
            "95 / 1875\n",
            "96 / 1875\n",
            "97 / 1875\n",
            "98 / 1875\n",
            "99 / 1875\n",
            "100 / 1875\n",
            "101 / 1875\n",
            "102 / 1875\n",
            "103 / 1875\n",
            "104 / 1875\n",
            "105 / 1875\n",
            "106 / 1875\n",
            "107 / 1875\n",
            "108 / 1875\n",
            "109 / 1875\n",
            "110 / 1875\n",
            "111 / 1875\n",
            "112 / 1875\n",
            "113 / 1875\n",
            "114 / 1875\n",
            "115 / 1875\n",
            "116 / 1875\n",
            "117 / 1875\n",
            "118 / 1875\n",
            "119 / 1875\n",
            "120 / 1875\n",
            "121 / 1875\n",
            "122 / 1875\n",
            "123 / 1875\n",
            "124 / 1875\n",
            "125 / 1875\n",
            "126 / 1875\n",
            "127 / 1875\n",
            "128 / 1875\n",
            "129 / 1875\n",
            "130 / 1875\n",
            "131 / 1875\n",
            "132 / 1875\n",
            "133 / 1875\n",
            "134 / 1875\n",
            "135 / 1875\n",
            "136 / 1875\n",
            "137 / 1875\n",
            "138 / 1875\n",
            "139 / 1875\n",
            "140 / 1875\n",
            "141 / 1875\n",
            "142 / 1875\n",
            "143 / 1875\n",
            "144 / 1875\n",
            "145 / 1875\n",
            "146 / 1875\n",
            "147 / 1875\n",
            "148 / 1875\n",
            "149 / 1875\n",
            "150 / 1875\n",
            "151 / 1875\n",
            "152 / 1875\n",
            "153 / 1875\n",
            "154 / 1875\n",
            "155 / 1875\n",
            "156 / 1875\n",
            "157 / 1875\n",
            "158 / 1875\n",
            "159 / 1875\n",
            "160 / 1875\n",
            "161 / 1875\n",
            "162 / 1875\n",
            "163 / 1875\n",
            "164 / 1875\n",
            "165 / 1875\n",
            "166 / 1875\n",
            "167 / 1875\n",
            "168 / 1875\n",
            "169 / 1875\n",
            "170 / 1875\n",
            "171 / 1875\n",
            "172 / 1875\n",
            "173 / 1875\n",
            "174 / 1875\n",
            "175 / 1875\n",
            "176 / 1875\n",
            "177 / 1875\n",
            "178 / 1875\n",
            "179 / 1875\n",
            "180 / 1875\n",
            "181 / 1875\n",
            "182 / 1875\n",
            "183 / 1875\n",
            "184 / 1875\n",
            "185 / 1875\n",
            "186 / 1875\n",
            "187 / 1875\n",
            "188 / 1875\n",
            "189 / 1875\n",
            "190 / 1875\n",
            "191 / 1875\n",
            "192 / 1875\n",
            "193 / 1875\n",
            "194 / 1875\n",
            "195 / 1875\n",
            "196 / 1875\n",
            "197 / 1875\n",
            "198 / 1875\n",
            "199 / 1875\n",
            "200 / 1875\n",
            "201 / 1875\n",
            "202 / 1875\n",
            "203 / 1875\n",
            "204 / 1875\n",
            "205 / 1875\n",
            "206 / 1875\n",
            "207 / 1875\n",
            "208 / 1875\n",
            "209 / 1875\n",
            "210 / 1875\n",
            "211 / 1875\n",
            "212 / 1875\n",
            "213 / 1875\n",
            "214 / 1875\n",
            "215 / 1875\n",
            "216 / 1875\n",
            "217 / 1875\n",
            "218 / 1875\n",
            "219 / 1875\n",
            "220 / 1875\n",
            "221 / 1875\n",
            "222 / 1875\n",
            "223 / 1875\n",
            "224 / 1875\n",
            "225 / 1875\n",
            "226 / 1875\n",
            "227 / 1875\n",
            "228 / 1875\n",
            "229 / 1875\n",
            "230 / 1875\n",
            "231 / 1875\n",
            "232 / 1875\n",
            "233 / 1875\n",
            "234 / 1875\n",
            "235 / 1875\n",
            "236 / 1875\n",
            "237 / 1875\n",
            "238 / 1875\n",
            "239 / 1875\n",
            "240 / 1875\n",
            "241 / 1875\n",
            "242 / 1875\n",
            "243 / 1875\n",
            "244 / 1875\n",
            "245 / 1875\n",
            "246 / 1875\n",
            "247 / 1875\n",
            "248 / 1875\n",
            "249 / 1875\n",
            "250 / 1875\n",
            "251 / 1875\n",
            "252 / 1875\n",
            "253 / 1875\n",
            "254 / 1875\n",
            "255 / 1875\n",
            "256 / 1875\n",
            "257 / 1875\n",
            "258 / 1875\n",
            "259 / 1875\n",
            "260 / 1875\n",
            "261 / 1875\n",
            "262 / 1875\n",
            "263 / 1875\n",
            "264 / 1875\n",
            "265 / 1875\n",
            "266 / 1875\n",
            "267 / 1875\n",
            "268 / 1875\n",
            "269 / 1875\n",
            "270 / 1875\n",
            "271 / 1875\n",
            "272 / 1875\n",
            "273 / 1875\n",
            "274 / 1875\n",
            "275 / 1875\n",
            "276 / 1875\n",
            "277 / 1875\n",
            "278 / 1875\n",
            "279 / 1875\n",
            "280 / 1875\n",
            "281 / 1875\n",
            "282 / 1875\n",
            "283 / 1875\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m gan\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels_b/discriminator.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m gan\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels_b/generator.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[39], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataset, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index_batch, image_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_batch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m generate_and_save_images(model\u001b[38;5;241m.\u001b[39mgenerator, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, SEED, img_dir)\n",
            "Cell \u001b[1;32mIn[34], line 34\u001b[0m, in \u001b[0;36mGAN.train_step\u001b[1;34m(self, real_images)\u001b[0m\n\u001b[0;32m     27\u001b[0m gradients_of_generator \u001b[38;5;241m=\u001b[39m gen_tape\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[0;32m     28\u001b[0m     ge_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m gradients_of_discriminator \u001b[38;5;241m=\u001b[39m disc_tape\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[0;32m     31\u001b[0m     di_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients_of_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mzip\u001b[39m(gradients_of_discriminator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: di_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: ge_loss}\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:344\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[0;32m    343\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:409\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[1;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[0;32m    406\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:472\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[1;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[0;32m    479\u001b[0m     )\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:120\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[1;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[0;32m    118\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m    119\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[1;32m--> 120\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[1;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[1;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(strategy, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[0;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:134\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[1;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[1;32m--> 134\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[0;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[0;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[0;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[1;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[0;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[0;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[0;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:131\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad, learning_rate)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\optimizers\\adam.py:117\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[1;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, gradient, variable, learning_rate):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update step given gradient and the associated model variable.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     lr \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(gradient, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    119\u001b[0m     local_step \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, variable\u001b[38;5;241m.\u001b[39mdtype)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\ops\\core.py:803\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cast(dtype\u001b[38;5;241m=\u001b[39mdtype)(x)\n\u001b[1;32m--> 803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:207\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1012\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1006\u001b[0m   x \u001b[38;5;241m=\u001b[39m indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_complex \u001b[38;5;129;01mand\u001b[39;00m base_type\u001b[38;5;241m.\u001b[39mis_floating:\n\u001b[0;32m   1014\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.  This will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard the imaginary part and may not be what you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m     )\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:732\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    731\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[0;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:85\u001b[0m, in \u001b[0;36mVariable.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2375\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_var_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1621\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1619\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1621\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:656\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    654\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_value\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 656\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:841\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    839\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    844\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    845\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    846\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    847\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    848\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    849\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:831\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    830\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 831\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32md:\\PyInterpreters\\Big_data\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:590\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    589\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    593\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(gan, train_dataset, EPOCHS)\n",
        "\n",
        "gan.discriminator.save(\"models_b/discriminator.keras\")\n",
        "gan.generator.save(\"models_b/generator.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6f7c8b0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "gan.discriminator.save(\"models_b/discriminator.keras\")\n",
        "gan.generator.save(\"models_b/generator.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b42e675f",
      "metadata": {
        "id": "b42e675f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvklEQVR4nO3dMU5UXRiAYYYwNjaEBq0s7VgAoXAHNJSsxVjqliwspCO2FCQ0JBQkhiExRk1MZtzAn3sHMzPg/z5P+53iNC9fcS4wWSwWiy3gf237sS8ArJ/QIUDoECB0CBA6BAgdAoQOAUKHAKFDwM6yByeTyTrvAfylZT5utdEhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUPAzmNfgM3b3h7/+b67uzs4n81mK7oNm2CjQ4DQIUDoECB0CBA6BAgdAoQOAd7Rgz59+jR65t27d4Pzz58/D87n8/lDrsSa2egQIHQIEDoECB0ChA4BQocAoUOAd/Sg169fj565vb0dnC8Wi1Vdhw2w0SFA6BAgdAgQOgQIHQKEDgFChwChQ4APZoLu7+9Hz7x48WJwfnl5uarrsAE2OgQIHQKEDgFChwChQ4DQIUDoEOAdPejnz5+jZ378+DE494cn/i02OgQIHQKEDgFChwChQ4DQIUDoEOAdPejVq1ejZ/b39wfn29vDO2I+nz/oTqyXjQ4BQocAoUOA0CFA6BAgdAgQOgR4Rw96/vz56Jlv374Nzv0++r/FRocAoUOA0CFA6BAgdAgQOgQIHQKEDgE+mAmaTqejZ3Z3dwfnk8lkcO6DmqfFRocAoUOA0CFA6BAgdAgQOgQIHQK8oweN/fOFra2trZubm8H52Ds6T4uNDgFChwChQ4DQIUDoECB0CBA6BHhH5z/t7e099hVYIRsdAoQOAUKHAKFDgNAhQOgQIHQI8I4etMzvks9ms8H5fD5f1XXYABsdAoQOAUKHAKFDgNAhQOgQIHQIEDoE+GAm6Pv376NnDg4OBucXFxeD81+/fj3oTqyXjQ4BQocAoUOA0CFA6BAgdAgQOgR4Rw+aTqejZ46PjwfnZ2dng/Orq6sH3Yn1stEhQOgQIHQIEDoECB0ChA4BQocA7+hBp6eno2c+fPgwOD85ORmcv3///kF3Yr1sdAgQOgQIHQKEDgFChwChQ4DQIcA7etDt7e3omevr68H52N9152mx0SFA6BAgdAgQOgQIHQKEDgFChwChQ4APZoLevHkzeubw8HBw/vbt2xXdhk2w0SFA6BAgdAgQOgQIHQKEDgFChwDv6EEvX74cPXN+fj44n06nq7oOG2CjQ4DQIUDoECB0CBA6BAgdAoQOAd7Rg2az2eiZo6Ojwfnd3d2qrsMG2OgQIHQIEDoECB0ChA4BQocAoUOAd/Sgr1+/jp75/fv34PzZs2erug4bYKNDgNAhQOgQIHQIEDoECB0ChA4BQocAH8wEffz4cfTM2AczX758WdV12AAbHQKEDgFChwChQ4DQIUDoECB0CJgsFovFUgcnk3XfBfgLyyRso0OA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFCh4CdZQ8u88/WgafJRocAoUOA0CFA6BAgdAgQOgQIHQKEDgFCh4A/eEN+FAGzi7oAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "noise = tf.random.normal([1, LATENT_DIM])\n",
        "generated_image = gan.generator(noise, training=False)\n",
        "\n",
        "draw_image(generated_image, generated_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714033c6",
      "metadata": {
        "id": "714033c6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Big_data",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
