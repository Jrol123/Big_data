{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195917a0-5f2c-4eae-a648-b3ea4d088c94",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/ProgUtilities/Python3_11/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from mlflow.tracking import MlflowClient\n",
    "from plotly.subplots import make_subplots\n",
    "import base64\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd978053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Получение информации об экспериментах\n",
    "experiments = mlflow.search_experiments()\n",
    "print(\"Доступные эксперименты:\")\n",
    "for exp in experiments:\n",
    "    print(f\"- {exp.name} (ID: {exp.experiment_id})\")\n",
    "\n",
    "# 2. Получение последних запусков\n",
    "experiment = client.get_experiment_by_name(\"California Housing Prediction\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "print(f\"\\nВсего запусков: {len(runs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a009d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Визуализация метрик\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# R2 score по моделям\n",
    "plt.subplot(2, 2, 1)\n",
    "model_r2 = runs.groupby(\"tags.mlflow.runName\")[\"metrics.r2_score\"].max()\n",
    "model_r2.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"R2 Score по моделям\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# MSE по моделям\n",
    "plt.subplot(2, 2, 2)\n",
    "model_mse = runs.groupby(\"tags.mlflow.runName\")[\"metrics.mse\"].min()\n",
    "model_mse.plot(kind=\"bar\", color=\"lightcoral\")\n",
    "plt.title(\"MSE по моделям\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Временная динамика метрик\n",
    "plt.subplot(2, 2, 3)\n",
    "runs[\"start_time\"] = pd.to_datetime(runs[\"start_time\"])\n",
    "latest_runs = runs.sort_values(\"start_time\").tail(10)\n",
    "plt.plot(\n",
    "    latest_runs[\"start_time\"],\n",
    "    latest_runs[\"metrics.r2_score\"],\n",
    "    marker=\"o\",\n",
    "    label=\"R2 Score\",\n",
    ")\n",
    "plt.plot(latest_runs[\"start_time\"], latest_runs[\"metrics.mse\"], marker=\"s\", label=\"MSE\")\n",
    "plt.title(\"Динамика метрик\")\n",
    "plt.xlabel(\"Время\")\n",
    "plt.ylabel(\"Значение\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Сравнение моделей\n",
    "plt.subplot(2, 2, 4)\n",
    "comparison_data = []\n",
    "for idx, run in runs.iterrows():\n",
    "    comparison_data.append(\n",
    "        {\n",
    "            \"model\": run[\"tags.mlflow.runName\"].split(\"_\")[0],\n",
    "            \"r2\": run[\"metrics.r2_score\"],\n",
    "            \"mse\": run[\"metrics.mse\"],\n",
    "            \"mae\": run[\"metrics.mae\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.groupby(\"model\").mean().plot(kind=\"bar\", ax=plt.gca())\n",
    "plt.title(\"Средние метрики по моделям\")\n",
    "plt.ylabel(\"Значение\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./metrics_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Загрузка артефактов для последнего запуска\n",
    "latest_run = runs.iloc[0]\n",
    "run_id = latest_run.run_id\n",
    "\n",
    "# Получение списка артефактов\n",
    "artifacts = client.list_artifacts(run_id)\n",
    "print(\"\\nАртефакты последнего запуска:\")\n",
    "for artifact in artifacts:\n",
    "    print(f\"- {artifact.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc433db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Загрузка и отображение графиков\n",
    "\n",
    "# Поиск графиков\n",
    "plot_artifacts = [a for a in artifacts if \"plots\" in a.path and a.path.endswith(\".png\")]\n",
    "\n",
    "print(\"\\nГрафики из последнего запуска:\")\n",
    "for plot in plot_artifacts[:3]:  # Показать первые 3 графика\n",
    "    try:\n",
    "        # Загрузка изображения\n",
    "        artifact_path = client.download_artifacts(run_id, plot.path)\n",
    "        display(Image(filename=artifact_path))\n",
    "        print(f\"График: {plot.path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка загрузки {plot.path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da52d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Анализ параметров моделей\n",
    "print(\"\\nПараметры лучших моделей:\")\n",
    "best_models = runs.sort_values(\"metrics.r2_score\", ascending=False).head(3)\n",
    "\n",
    "for idx, run in best_models.iterrows():\n",
    "    print(f\"\\nМодель: {run['tags.mlflow.runName']}\")\n",
    "    print(f\"R2 Score: {run['metrics.r2_score']:.4f}\")\n",
    "    print(f\"MSE: {run['metrics.mse']:.4f}\")\n",
    "    print(f\"MAE: {run['metrics.mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91feac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Создание интерактивной дашборда\n",
    "\n",
    "# Создание интерактивного графика\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        \"R2 Score по моделям\",\n",
    "        \"MSE по моделям\",\n",
    "        \"Динамика R2 Score\",\n",
    "        \"Сравнение метрик\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# График 1: R2 Score\n",
    "fig.add_trace(\n",
    "    go.Bar(x=model_r2.index, y=model_r2.values, name=\"R2 Score\"), row=1, col=1\n",
    ")\n",
    "\n",
    "# График 2: MSE\n",
    "fig.add_trace(go.Bar(x=model_mse.index, y=model_mse.values, name=\"MSE\"), row=1, col=2)\n",
    "\n",
    "# График 3: Динамика\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=latest_runs[\"start_time\"],\n",
    "        y=latest_runs[\"metrics.r2_score\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"R2 Score\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# График 4: Сравнение\n",
    "for metric in [\"r2\", \"mse\", \"mae\"]:\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=comparison_df[\"model\"].unique(),\n",
    "            y=comparison_df.groupby(\"model\")[metric].mean(),\n",
    "            name=metric.upper(),\n",
    "        ),\n",
    "        row=2,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=800, showlegend=True, title_text=\"Анализ моделей MLflow\")\n",
    "fig.write_html(\"./model_analysis_dashboard.html\")\n",
    "print(\"\\nИнтерактивная дашборда сохранена в model_analysis_dashboard.html\")\n",
    "\n",
    "# 8. Отчет о качестве моделей\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ОТЧЕТ О КАЧЕСТВЕ МОДЕЛЕЙ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_run = runs.iloc[runs[\"metrics.r2_score\"].idxmax()]\n",
    "worst_run = runs.iloc[runs[\"metrics.r2_score\"].idxmin()]\n",
    "\n",
    "print(f\"\\nЛучшая модель: {best_run['tags.mlflow.runName']}\")\n",
    "print(f\"Лучший R2 Score: {best_run['metrics.r2_score']:.4f}\")\n",
    "print(f\"\\nХудшая модель: {worst_run['tags.mlflow.runName']}\")\n",
    "print(f\"Худший R2 Score: {worst_run['metrics.r2_score']:.4f}\")\n",
    "print(\n",
    "    f\"\\nРазница в качестве: {(best_run['metrics.r2_score'] - worst_run['metrics.r2_score']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800860ae-93eb-4d93-b666-f2a842de71f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
