{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:16:57.345213Z",
     "start_time": "2024-10-03T04:16:50.188864Z"
    }
   },
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "# Загрузка английской NLP-модели\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mspacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlang\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01men\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m English\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Загрузка английской NLP-модели\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mspacy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men_core_web_sm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Utilities\\IDLE\\lib\\site-packages\\spacy\\__init__.py:51\u001B[0m, in \u001B[0;36mload\u001B[1;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\n\u001B[0;32m     28\u001B[0m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     34\u001B[0m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mSimpleFrozenDict(),\n\u001B[0;32m     35\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Language:\n\u001B[0;32m     36\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \n\u001B[0;32m     38\u001B[0m \u001B[38;5;124;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Utilities\\IDLE\\lib\\site-packages\\spacy\\util.py:472\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m OLD_MODEL_SHORTCUTS:\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE941\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname, full\u001B[38;5;241m=\u001B[39mOLD_MODEL_SHORTCUTS[name]))  \u001B[38;5;66;03m# type: ignore[index]\u001B[39;00m\n\u001B[1;32m--> 472\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE050\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname))\n",
      "\u001B[1;31mOSError\u001B[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"London is the capital and most populous city of England and \n",
    "the United Kingdom.  Standing on the River Thames in the south east \n",
    "of the island of Great Britain, London has been a major settlement \n",
    "for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:16:57.363355Z",
     "start_time": "2024-10-03T04:16:57.362349Z"
    }
   },
   "id": "aa317a42f92e155c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Парсинг текста с помощью spaCy. Эта команда запускает целый конвейер\n",
    "doc = nlp(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:16:57.370350Z",
     "start_time": "2024-10-03T04:16:57.368348Z"
    }
   },
   "id": "b97b406c8618e05f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# например, распечатать все обнаруженные именованные сущности\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12e0dc31de7d0a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Если токен является именем, заменяем его словом \"REDACTED\" \n",
    "def replace_name_with_placeholder(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    else:\n",
    "        return token.text\n",
    "\n",
    "# Проверка всех сущностей\n",
    "# Loop through all the entities in a document and check if they are names\n",
    "def scrub(text):\n",
    "    doc = nlp(text)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    tokens = map(replace_name_with_placeholder, doc)\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "s = \"\"\"\n",
    "In 1950, Alan Turing published his famous article \"Computing Machinery and Intelligence\". \n",
    "In 1957, Noam Chomsky’s \n",
    " Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of \n",
    " syntactic structures.\n",
    " \"\"\"\n",
    "\n",
    "print(scrub(s))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3825069afacd31a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from spacy.lang.ru import Russian\n",
    "nlp = Russian()\n",
    "doc = nlp(\"Съешь ещё этих мягких французских булок, да выпей чаю.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27666dcff8b5c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "token = doc[0]\n",
    "print(token.text)\n",
    "\n",
    "span = doc[3:6]\n",
    "print(span.text)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c308cb1bc3de1f37",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"is_alpha:    \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:    \", [token.is_punct for token in doc])\n",
    "print(\"like_num:    \", [token.like_num for token in doc])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1714eab7b550fa07",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for token in doc:\n",
    "    if token.i+1 < len(doc):\n",
    "        next_token = doc[token.i+1]\n",
    "        if next_token.text == \".\":\n",
    "            print(token.text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e167f827c72f2163",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"New Apple MacBook set launch tomorrow\")\n",
    "\n",
    "for token in doc:\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    token_head = token.head.text\n",
    "    print(f\"{token_text:<12}{token_pos:<10}\"\n",
    "          f\"{token_dep:<10}{token_head:<12}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "377720459e75c746",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b976453a926f7698",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(spacy.explain(\"aux\"))\n",
    "print(spacy.explain(\"PROPN\"))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32900fbe8631cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I saw a movie yesterday\")\n",
    "print(' '.join([token.lemma_ for token in doc]))\n",
    "\n",
    "'-PRON- see a movie yesterday'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e893ed99270d98",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for 1$ billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4b13547e951aeb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(spacy.explain(\"GPE\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a9548102b376cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b159d09d6d2e9b92",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc1 = nlp(\"I like burgers\")\n",
    "doc2 = nlp(\"I like pizza\")\n",
    "print(doc1.similarity(doc2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13227631ce3e6959",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# отсюда сама лекция"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a286f283f8bed66",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "# Загружаем языковую модель\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Входной текст\n",
    "text = \"spaCy is an amazing tool for natural language processing.\"\n",
    "\n",
    "# Применяем токенизацию\n",
    "doc = nlp(text)\n",
    "\n",
    "# Выводим токены (слова и пунктуацию) из текста\n",
    "for token in doc:\n",
    "    print(token.text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9e8895915e7aea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "# Загружаем языковую модель\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Входной текст с несколькими предложениями\n",
    "text = \"SpaCy is fast. It's also efficient.\"\n",
    "\n",
    "# Применяем разбиение на предложения\n",
    "doc = nlp(text)\n",
    "\n",
    "# Выводим предложения из текста\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13311131e313364a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"running dogs are happily barking\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2cd133284ad6ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d72f85d5b0bced",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b53cee3a3fec70c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b3e760e6fc1274",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
